{
 "PRed":[
  {
   "PR":{
    "__lazy_json__":"pr_json/240317755.json"
   },
   "data":{
    "bot_rerun":false,
    "migrator_name":"CompilerRebuild",
    "migrator_version":1,
    "name":"Python 3.7, GCC 7, R 3.5.1, openBLAS 0.3.2"
   },
   "keys":[
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "name"
   ]
  },
  {
   "data":{
    "bot_rerun":false,
    "migrator_name":"Version",
    "migrator_version":0,
    "version":"0.5.0"
   },
   "keys":[
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "data":{
    "bot_rerun":false,
    "migrator_name":"Version",
    "migrator_version":0,
    "version":"0.5.1"
   },
   "keys":[
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR":{
    "__lazy_json__":"pr_json/253876268.json"
   },
   "data":{
    "bot_rerun":false,
    "migrator_name":"Version",
    "migrator_version":0,
    "version":"0.6.1"
   },
   "keys":[
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR":{
    "__lazy_json__":"pr_json/273670544.json"
   },
   "data":{
    "bot_rerun":false,
    "migrator_name":"Version",
    "migrator_version":0,
    "version":"0.6.2"
   },
   "keys":[
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR":{
    "__lazy_json__":"pr_json/336082964.json"
   },
   "data":{
    "bot_rerun":false,
    "migrator_name":"MigrationYaml",
    "migrator_object_version":1,
    "migrator_version":0,
    "name":"python38"
   },
   "keys":[
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  }
 ],
 "bad":false,
 "conda-forge.yml":{
  "compiler_stack":"comp7",
  "max_py_ver":"37",
  "max_r_ver":"35"
 },
 "feedstock_name":"pytorch-pretrained-bert",
 "hash_type":"sha256",
 "meta_yaml":{
  "about":{
   "description":"This repository contains op-for-op PyTorch reimplementations, pre-trained\nmodels and fine-tuning examples for:\n  - Google's BERT model,\n  - OpenAI's GPT model,\n  - Google/CMU's Transformer-XL model, and\n  - OpenAI's GPT-2 model.\nThese implementations have been tested on several datasets (see the\nexamples) and should match the performances of the associated TensorFlow\nimplementations (e.g. ~91 F1 on SQuAD for BERT, ~88 F1 on RocStories for\nOpenAI GPT and ~18.3 perplexity on WikiText 103 for the Transformer-XL).\n",
   "home":"https://github.com/huggingface/pytorch-pretrained-BERT",
   "license":"Apache-2.0",
   "license_family":"Apache",
   "license_file":"LICENSE",
   "summary":"PyTorch version of Google AI BERT model with script to load Google pre-trained models"
  },
  "build":{
   "entry_points":[
    "pytorch-pretrained-bert = pytorch_pretrained_bert.__main__:main",
    "pytorch_pretrained_bert = pytorch_pretrained_bert.__main__:main",
    "pytorch-pretrained-bert = pytorch_pretrained_bert.__main__:main",
    "pytorch_pretrained_bert = pytorch_pretrained_bert.__main__:main",
    "pytorch-pretrained-bert = pytorch_pretrained_bert.__main__:main",
    "pytorch_pretrained_bert = pytorch_pretrained_bert.__main__:main"
   ],
   "number":"0",
   "script":" -m pip install . --no-deps -vv",
   "skip":true
  },
  "extra":{
   "recipe-maintainers":[
    "CurtLH",
    "sodre",
    "CurtLH",
    "sodre",
    "CurtLH",
    "sodre"
   ]
  },
  "package":{
   "name":"pytorch-pretrained-bert",
   "version":"0.6.2"
  },
  "requirements":{
   "host":[
    "python",
    "pip",
    "python",
    "pip",
    "python",
    "pip"
   ],
   "run":[
    "boto3",
    "numpy",
    "python",
    "regex",
    "requests",
    "tqdm",
    "boto3",
    "numpy",
    "python",
    "regex",
    "requests",
    "tqdm",
    "boto3",
    "numpy",
    "python",
    "regex",
    "requests",
    "tqdm"
   ]
  },
  "source":{
   "sha256":"9cf7c6221e854071b9844f2a9a581e05a24777351618c010493d9c76601c6747",
   "url":"https://pypi.io/packages/source/p/pytorch-pretrained-bert/pytorch_pretrained_bert-0.6.2.tar.gz"
  },
  "test":{
   "imports":[
    "pytorch_pretrained_bert",
    "pytorch_pretrained_bert",
    "pytorch_pretrained_bert"
   ],
   "requires":[
    "pytorch-cpu",
    "pytorch-cpu",
    "pytorch-cpu"
   ]
  }
 },
 "name":"pytorch-pretrained-bert",
 "new_version":"0.6.2",
 "pinning_version":"2019.11.01",
 "raw_meta_yaml":"{% set name = \"pytorch-pretrained-bert\" %}\n{% set version = \"0.6.2\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name.replace('-','_') }}-{{ version }}.tar.gz\n  sha256: 9cf7c6221e854071b9844f2a9a581e05a24777351618c010493d9c76601c6747\n\nbuild:\n  skip: True  # [not linux or py<35]\n  number: 0\n  script: \"{{ PYTHON }} -m pip install . --no-deps -vv\"\n  entry_points:\n    - pytorch-pretrained-bert = pytorch_pretrained_bert.__main__:main\n    - pytorch_pretrained_bert = pytorch_pretrained_bert.__main__:main\n\nrequirements:\n  host:\n    - python\n    - pip\n  run:\n    - boto3\n    - numpy\n    - python\n    - regex\n    - requests\n    - tqdm\n\ntest:\n  requires:\n    - pytorch-cpu\n  imports:\n    - pytorch_pretrained_bert\n\nabout:\n  home: https://github.com/huggingface/pytorch-pretrained-BERT\n  license: Apache-2.0\n  license_family: Apache\n  license_file: LICENSE\n  summary: 'PyTorch version of Google AI BERT model with script to load Google pre-trained models'\n  description: |\n    This repository contains op-for-op PyTorch reimplementations, pre-trained\n    models and fine-tuning examples for:\n      - Google's BERT model,\n      - OpenAI's GPT model,\n      - Google/CMU's Transformer-XL model, and\n      - OpenAI's GPT-2 model.\n    These implementations have been tested on several datasets (see the\n    examples) and should match the performances of the associated TensorFlow\n    implementations (e.g. ~91 F1 on SQuAD for BERT, ~88 F1 on RocStories for\n    OpenAI GPT and ~18.3 perplexity on WikiText 103 for the Transformer-XL).\n\nextra:\n  recipe-maintainers:\n    - CurtLH\n    - sodre\n",
 "req":{
  "__set__":true,
  "elements":[
   "boto3",
   "numpy",
   "pip",
   "python",
   "regex",
   "requests",
   "tqdm"
  ]
 },
 "requirements":{
  "build":{
   "__set__":true,
   "elements":[]
  },
  "host":{
   "__set__":true,
   "elements":[
    "pip",
    "python"
   ]
  },
  "run":{
   "__set__":true,
   "elements":[
    "boto3",
    "numpy",
    "python",
    "regex",
    "requests",
    "tqdm"
   ]
  },
  "test":{
   "__set__":true,
   "elements":[
    "pytorch-cpu"
   ]
  }
 },
 "smithy_version":"3.6.1",
 "strong_exports":false,
 "total_requirements":{
  "build":{
   "__set__":true,
   "elements":[]
  },
  "host":{
   "__set__":true,
   "elements":[
    "pip",
    "python"
   ]
  },
  "run":{
   "__set__":true,
   "elements":[
    "boto3",
    "numpy",
    "python",
    "regex",
    "requests",
    "tqdm"
   ]
  },
  "test":{
   "__set__":true,
   "elements":[
    "pytorch-cpu"
   ]
  }
 },
 "url":"https://pypi.io/packages/source/p/pytorch-pretrained-bert/pytorch_pretrained_bert-0.6.2.tar.gz",
 "version":"0.6.2"
}