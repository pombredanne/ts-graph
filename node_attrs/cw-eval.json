{
 "PRed":[
  {
   "PR":{
    "__lazy_json__":"pr_json/239238044.json"
   },
   "data":{
    "bot_rerun":false,
    "migrator_name":"Version",
    "migrator_version":0,
    "version":"0.3.1"
   },
   "keys":[
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR":{
    "__lazy_json__":"pr_json/239238298.json"
   },
   "data":{
    "bot_rerun":false,
    "migrator_name":"CompilerRebuild",
    "migrator_version":1,
    "name":"Python 3.7, GCC 7, R 3.5.1, openBLAS 0.3.2"
   },
   "keys":[
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR":{
    "__lazy_json__":"pr_json/242375260.json"
   },
   "data":{
    "bot_rerun":false,
    "migrator_name":"Version",
    "migrator_version":0,
    "version":"1.0.0"
   },
   "keys":[
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "version"
   ]
  },
  {
   "PR":{
    "__lazy_json__":"pr_json/336109970.json"
   },
   "data":{
    "bot_rerun":false,
    "migrator_name":"MigrationYaml",
    "migrator_object_version":1,
    "migrator_version":0,
    "name":"python38"
   },
   "keys":[
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  }
 ],
 "bad":false,
 "conda-forge.yml":{
  "compiler_stack":"comp7",
  "max_py_ver":"37",
  "max_r_ver":"35",
  "provider":{
   "win":"azure"
  }
 },
 "feedstock_name":"cw-eval",
 "hash_type":"sha256",
 "meta_yaml":{
  "about":{
   "description":"cw-eval is an evaluation suite for scoring entries in geospatial image\nanalysis competitions. It includes tools for calculating IoU scores,\nprecision, recall, F1 score, and scripts to score entire entries in either\ngeojson or csv formats.\n",
   "dev_url":"https://github.com/cosmiq/cw-eval",
   "doc_url":"http://cw-eval.readthedocs.io/",
   "home":"http://github.com/cosmiq/cw-eval",
   "license":"Apache-2.0",
   "license_family":"Apache",
   "license_file":"/LICENSE.txt",
   "summary":"Evaluation metrics for Geospatial Machine Learning Challenges"
  },
  "build":{
   "number":"1000",
   "script":" -m pip install . --no-deps -vv"
  },
  "extra":{
   "recipe-maintainers":[
    "nrweir",
    "nrweir",
    "nrweir"
   ]
  },
  "package":{
   "name":"cw-eval",
   "version":"1.0.0"
  },
  "requirements":{
   "build":[
    "c_compiler_stub",
    "c_compiler_stub",
    "c_compiler_stub"
   ],
   "host":[
    "python",
    "pip",
    "python",
    "pip",
    "python",
    "pip"
   ],
   "run":[
    "python",
    "rtree",
    "shapely",
    "pandas",
    "geopandas",
    "tqdm",
    "python",
    "rtree",
    "shapely",
    "pandas",
    "geopandas",
    "tqdm",
    "python",
    "rtree",
    "shapely",
    "pandas",
    "geopandas",
    "tqdm"
   ]
  },
  "source":{
   "sha256":"786da1252f274b84a326532569337d2fbb872aaad1132b88c72b8de473b9ddf3",
   "url":"https://pypi.io/packages/source/c/cw-eval/cw_eval-1.0.0.tar.gz"
  },
  "test":{
   "imports":"cw_eval"
  }
 },
 "name":"cw-eval",
 "new_version":"1.0.0",
 "pinning_version":"2019.11.01",
 "raw_meta_yaml":"{% set name = \"cw-eval\" %}\n{% set version = \"1.0.0\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name|replace(\"-\",\"_\") }}-{{ version }}.tar.gz\n  sha256: 786da1252f274b84a326532569337d2fbb872aaad1132b88c72b8de473b9ddf3\n\n\nbuild:\n  number: 1000\n  script: \"{{ PYTHON }} -m pip install . --no-deps -vv\"\n\nrequirements:\n  build:\n    - {{ compiler('c') }}\n  host:\n    - python\n    - pip\n  run:\n    - python\n    - rtree\n    - shapely\n    - pandas\n    - geopandas\n    - tqdm\n\ntest:\n  imports:\n    cw_eval\n\nabout:\n  home: http://github.com/cosmiq/cw-eval\n  license: Apache-2.0\n  license_family: Apache\n  license_file: '{{ environ[\"RECIPE_DIR\"] }}/LICENSE.txt'\n  summary: 'Evaluation metrics for Geospatial Machine Learning Challenges'\n\n  description: |\n    cw-eval is an evaluation suite for scoring entries in geospatial image\n    analysis competitions. It includes tools for calculating IoU scores,\n    precision, recall, F1 score, and scripts to score entire entries in either\n    geojson or csv formats.\n  doc_url: http://cw-eval.readthedocs.io/\n  dev_url: https://github.com/cosmiq/cw-eval\n\nextra:\n  recipe-maintainers:\n    - nrweir\n",
 "req":{
  "__set__":true,
  "elements":[
   "c_compiler_stub",
   "geopandas",
   "pandas",
   "pip",
   "python",
   "rtree",
   "shapely",
   "tqdm"
  ]
 },
 "requirements":{
  "build":{
   "__set__":true,
   "elements":[
    "c_compiler_stub"
   ]
  },
  "host":{
   "__set__":true,
   "elements":[
    "pip",
    "python"
   ]
  },
  "run":{
   "__set__":true,
   "elements":[
    "geopandas",
    "pandas",
    "python",
    "rtree",
    "shapely",
    "tqdm"
   ]
  },
  "test":{
   "__set__":true,
   "elements":[]
  }
 },
 "smithy_version":"3.6.1",
 "strong_exports":false,
 "total_requirements":{
  "build":{
   "__set__":true,
   "elements":[
    "c_compiler_stub"
   ]
  },
  "host":{
   "__set__":true,
   "elements":[
    "pip",
    "python"
   ]
  },
  "run":{
   "__set__":true,
   "elements":[
    "geopandas",
    "pandas",
    "python",
    "rtree",
    "shapely",
    "tqdm"
   ]
  },
  "test":{
   "__set__":true,
   "elements":[]
  }
 },
 "url":"https://pypi.io/packages/source/c/cw-eval/cw_eval-1.0.0.tar.gz",
 "version":"1.0.0"
}