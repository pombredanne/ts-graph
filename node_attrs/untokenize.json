{
 "bad":false,
 "conda-forge.yml":{},
 "feedstock_name":"untokenize",
 "hash_type":"sha256",
 "meta_yaml":{
  "about":{
   "description":"untokenize transforms tokens into source code. Unlike the standard\nlibrary's tokenize.untokenize(), it preserves the original whitespace between tokens.\n",
   "dev_url":"https://github.com/myint/untokenize",
   "home":"https://github.com/myint/untokenize",
   "license":"MIT",
   "license_family":"MIT",
   "license_file":"LICENSE",
   "summary":"Transforms tokens into original source code"
  },
  "build":{
   "noarch":"python",
   "number":"0",
   "script":" -m pip install . -vv"
  },
  "extra":{
   "recipe-maintainers":[
    "carlodri",
    "carlodri",
    "carlodri"
   ]
  },
  "package":{
   "name":"untokenize",
   "version":"0.1.1"
  },
  "requirements":{
   "host":[
    "python",
    "pip",
    "python",
    "pip",
    "python",
    "pip"
   ],
   "run":[
    "python",
    "python",
    "python"
   ]
  },
  "source":{
   "sha256":"3865dbbbb8efb4bb5eaa72f1be7f3e0be00ea8b7f125c69cbd1f5fda926f37a2",
   "url":"https://pypi.io/packages/source/u/untokenize/untokenize-0.1.1.tar.gz"
  },
  "test":{
   "imports":[
    "untokenize",
    "untokenize",
    "untokenize"
   ]
  }
 },
 "name":"untokenize",
 "new_version":"0.1.1",
 "raw_meta_yaml":"{% set name = \"untokenize\" %}\n{% set version = \"0.1.1\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz\n  sha256: 3865dbbbb8efb4bb5eaa72f1be7f3e0be00ea8b7f125c69cbd1f5fda926f37a2\n\nbuild:\n  noarch: python\n  number: 0\n  script: \"{{ PYTHON }} -m pip install . -vv\"\n\nrequirements:\n  host:\n    - python\n    - pip\n  run:\n    - python\n\ntest:\n  imports:\n    - untokenize\n\nabout:\n  home: https://github.com/myint/untokenize\n  license: MIT\n  license_family: MIT\n  license_file: LICENSE\n  summary: 'Transforms tokens into original source code'\n  description: |\n    untokenize transforms tokens into source code. Unlike the standard \n    library's tokenize.untokenize(), it preserves the original whitespace between tokens.\n  dev_url: https://github.com/myint/untokenize\n\nextra:\n  recipe-maintainers:\n    - carlodri\n",
 "req":{
  "__set__":true,
  "elements":[
   "pip",
   "python"
  ]
 },
 "requirements":{
  "build":{
   "__set__":true,
   "elements":[]
  },
  "host":{
   "__set__":true,
   "elements":[
    "pip",
    "python"
   ]
  },
  "run":{
   "__set__":true,
   "elements":[
    "python"
   ]
  },
  "test":{
   "__set__":true,
   "elements":[]
  }
 },
 "strong_exports":false,
 "total_requirements":{
  "build":{
   "__set__":true,
   "elements":[]
  },
  "host":{
   "__set__":true,
   "elements":[
    "pip",
    "python"
   ]
  },
  "run":{
   "__set__":true,
   "elements":[
    "python"
   ]
  },
  "test":{
   "__set__":true,
   "elements":[]
  }
 },
 "url":"https://pypi.io/packages/source/u/untokenize/untokenize-0.1.1.tar.gz",
 "version":"0.1.1"
}