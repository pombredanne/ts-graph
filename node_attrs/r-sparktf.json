{
 "PRed":[
  {
   "PR":{
    "__lazy_json__":"pr_json/299533513.json"
   },
   "data":{
    "bot_rerun":false,
    "migrator_name":"RBaseRebuild",
    "migrator_version":0,
    "name":"r-base-3.6.1"
   },
   "keys":[
    "bot_rerun",
    "migrator_name",
    "migrator_version",
    "name"
   ]
  },
  {
   "PR":{
    "__lazy_json__":"pr_json/413295691.json"
   },
   "data":{
    "bot_rerun":false,
    "migrator_name":"MigrationYaml",
    "migrator_object_version":2,
    "migrator_version":0,
    "name":"r400"
   },
   "keys":[
    "bot_rerun",
    "migrator_name",
    "migrator_object_version",
    "migrator_version",
    "name"
   ]
  }
 ],
 "bad":false,
 "conda-forge.yml":{
  "bot":{
   "automerge":true
  },
  "provider":{
   "win":"azure"
  }
 },
 "feedstock_name":"r-sparktf",
 "hash_type":"sha256",
 "meta_yaml":{
  "about":{
   "home":"https://CRAN.R-project.org/package=sparktf",
   "license":"Apache-2.0",
   "license_family":"APACHE",
   "license_file":"LICENSE-2.0.txt",
   "summary":"A 'sparklyr' extension that enables reading and writing 'TensorFlow' TFRecord files via 'Apache Spark'."
  },
  "build":{
   "merge_build_host":true,
   "noarch":"generic",
   "number":"2",
   "rpaths":[
    "lib/R/lib/",
    "lib/",
    "lib/R/lib/",
    "lib/",
    "lib/R/lib/",
    "lib/"
   ]
  },
  "extra":{
   "recipe-maintainers":[
    "conda-forge/r",
    "conda-forge/r",
    "conda-forge/r"
   ]
  },
  "package":{
   "name":"r-sparktf",
   "version":"0.1.0"
  },
  "requirements":{
   "build":null,
   "host":[
    "r-base",
    "r-sparklyr >=1.0",
    "r-base",
    "r-sparklyr >=1.0",
    "r-base",
    "r-sparklyr >=1.0"
   ],
   "run":[
    "r-base",
    "r-sparklyr >=1.0",
    "r-base",
    "r-sparklyr >=1.0",
    "r-base",
    "r-sparklyr >=1.0"
   ]
  },
  "source":{
   "sha256":"a46bcb0b26636b87ee72047f54c18bbea2a1855c1d72b31b057894722c0aa049",
   "url":[
    "https://cran.r-project.org/src/contrib/sparktf_0.1.0.tar.gz",
    "https://cran.r-project.org/src/contrib/Archive/sparktf/sparktf_0.1.0.tar.gz",
    "https://cran.r-project.org/src/contrib/sparktf_0.1.0.tar.gz",
    "https://cran.r-project.org/src/contrib/Archive/sparktf/sparktf_0.1.0.tar.gz",
    "https://cran.r-project.org/src/contrib/sparktf_0.1.0.tar.gz",
    "https://cran.r-project.org/src/contrib/Archive/sparktf/sparktf_0.1.0.tar.gz"
   ]
  },
  "test":{
   "commands":[
    "\"%R%\" -e \"library('sparktf')\"",
    "$R -e \"library('sparktf')\"",
    "$R -e \"library('sparktf')\""
   ]
  }
 },
 "name":"r-sparktf",
 "new_version":"0.1.0",
 "pinning_version":"2020.05.04.19.59.17",
 "raw_meta_yaml":"{% set version = \"0.1.0\" %}\n{% set posix = 'm2-' if win else '' %}\n{% set native = 'm2w64-' if win else '' %}\n\npackage:\n  name: r-sparktf\n  version: {{ version|replace(\"-\", \"_\") }}\n\nsource:\n  url:\n    - {{ cran_mirror }}/src/contrib/sparktf_{{ version }}.tar.gz\n    - {{ cran_mirror }}/src/contrib/Archive/sparktf/sparktf_{{ version }}.tar.gz\n  sha256: a46bcb0b26636b87ee72047f54c18bbea2a1855c1d72b31b057894722c0aa049\n\nbuild:\n  merge_build_host: true  # [win]\n  number: 2\n  noarch: generic\n  rpaths:\n    - lib/R/lib/\n    - lib/\n\nrequirements:\n  build:\n    - {{ posix }}zip               # [win]\n  host:\n    - r-base\n    - r-sparklyr >=1.0\n  run:\n    - r-base\n    - r-sparklyr >=1.0\n\ntest:\n  commands:\n    - $R -e \"library('sparktf')\"           # [not win]\n    - \"\\\"%R%\\\" -e \\\"library('sparktf')\\\"\"  # [win]\n\nabout:\n  home: https://CRAN.R-project.org/package=sparktf\n  license: Apache-2.0\n  summary: A 'sparklyr' extension that enables reading and writing 'TensorFlow' TFRecord files via 'Apache Spark'.\n  license_family: APACHE\n  license_file: LICENSE-2.0.txt\n\nextra:\n  recipe-maintainers:\n    - conda-forge/r\n\n# Package: sparktf\n# Type: Package\n# Title: Interface for 'TensorFlow' 'TFRecord' Files with 'Apache Spark'\n# Version: 0.1.0\n# Authors@R: c( person(\"Kevin\", \"Kuo\", role = c(\"aut\", \"cre\"), email = \"kevin.kuo@rstudio.com\", comment = c(ORCID = \"0000-0001-7803-7901\")) )\n# Description: A 'sparklyr' extension that enables reading and writing 'TensorFlow' TFRecord files via 'Apache Spark'.\n# License: Apache License (>= 2.0)\n# Encoding: UTF-8\n# SystemRequirements: TensorFlow (https://www.tensorflow.org/)\n# LazyData: true\n# Depends: R (>= 3.1.2)\n# Imports: sparklyr (>= 1.0)\n# RoxygenNote: 6.1.0\n# Suggests: testthat, dplyr\n# NeedsCompilation: no\n# Packaged: 2019-02-26 22:12:47 UTC; kevinykuo\n# Author: Kevin Kuo [aut, cre] (<https://orcid.org/0000-0001-7803-7901>)\n# Maintainer: Kevin Kuo <kevin.kuo@rstudio.com>\n# Repository: CRAN\n# Date/Publication: 2019-03-05 14:30:03 UTC\n",
 "req":{
  "__set__":true,
  "elements":[
   "r-base",
   "r-sparklyr"
  ]
 },
 "requirements":{
  "build":{
   "__set__":true,
   "elements":[]
  },
  "host":{
   "__set__":true,
   "elements":[
    "r-base",
    "r-sparklyr"
   ]
  },
  "run":{
   "__set__":true,
   "elements":[
    "r-base",
    "r-sparklyr"
   ]
  },
  "test":{
   "__set__":true,
   "elements":[]
  }
 },
 "smithy_version":"No azure token. Create a token and\nput it in ~/.conda-smithy/azure.token\n3.7.0\n",
 "strong_exports":false,
 "total_requirements":{
  "build":{
   "__set__":true,
   "elements":[]
  },
  "host":{
   "__set__":true,
   "elements":[
    "r-base",
    "r-sparklyr >=1.0"
   ]
  },
  "run":{
   "__set__":true,
   "elements":[
    "r-base",
    "r-sparklyr >=1.0"
   ]
  },
  "test":{
   "__set__":true,
   "elements":[]
  }
 },
 "url":[
  "https://cran.r-project.org/src/contrib/sparktf_0.1.0.tar.gz",
  "https://cran.r-project.org/src/contrib/Archive/sparktf/sparktf_0.1.0.tar.gz",
  "https://cran.r-project.org/src/contrib/sparktf_0.1.0.tar.gz",
  "https://cran.r-project.org/src/contrib/Archive/sparktf/sparktf_0.1.0.tar.gz",
  "https://cran.r-project.org/src/contrib/sparktf_0.1.0.tar.gz",
  "https://cran.r-project.org/src/contrib/Archive/sparktf/sparktf_0.1.0.tar.gz"
 ],
 "version":"0.1.0"
}